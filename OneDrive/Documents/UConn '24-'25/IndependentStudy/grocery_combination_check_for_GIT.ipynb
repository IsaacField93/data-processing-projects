{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, itertools\n",
    "\n",
    "def process_data(data):\n",
    "\n",
    "    df_year_and_quarter = pd.read_csv(data)\n",
    "    \n",
    "    #Make a list of item column names\n",
    "    columns_as_string = \"Item 1\tItem 2\tItem 3\tItem 4\tItem 5\tItem 6\tItem 7\tItem 8\tItem 9\tItem 10\tItem 11\tItem 12\tItem 13\tItem 14\tItem 15\tItem 16\tItem 17\tItem 18\tItem 19\tItem 20\tItem 21\tItem 22\tItem 23\tItem 24\tItem 25\tItem 26\tItem 27\tItem 28\tItem 29\tItem 30\tItem 31\tItem 32\"\n",
    "    columns_as_list = columns_as_string.split('\t')\n",
    "\n",
    "    #Only include rows where item count is two or more\n",
    "    processed_df= df_year_and_quarter.loc [ df_year_and_quarter [\"Items(s)\"] > 2]\n",
    "\n",
    "    #Make a list of combinations of each column\n",
    "    item_column_combinations = itertools.combinations(columns_as_list, 2)\n",
    "    \n",
    "    #Make new columns for each possible column combination\n",
    "    for column_a, column_b in item_column_combinations:\n",
    "        processed_df [f'{column_a}_and_{column_b}_pair'] = processed_df [f'{column_a}'].astype(str) + '-' + processed_df [f'{column_b}'].astype(str)\n",
    "\n",
    "    #for i in range(len(itertools.combinations(processed_df.columns, 2))):\n",
    "        #for j in range(len(processed_df.columns)):\n",
    "            #for a, b in itertools.combinations(processed_df.columns, 2)\n",
    "                #processed_df [f'item_{a}_and_{b}_pair'] = processed_df [f'{a}'].astype(str) + '-' + processed_df [f'{b}'].astype(str)\n",
    "    \n",
    "    #Drop individual item columns, leaving only our item combo columns\n",
    "    processed_df.drop(columns = columns_as_list, inplace=True)\n",
    "    \n",
    "    #Make a list of the actual unique items in existing columns\n",
    "    unique_items = []\n",
    "    for i in columns_as_list:\n",
    "        unique_items.append(processed_df[f'{i}'].unique())\n",
    "    \n",
    "    return processed_df, unique_items\n",
    "\n",
    "    \n",
    "\n",
    "def check (processed_df, column_name, item_a, item_b):\n",
    "    return len (processed_df [ processed_df [ column_name ] == str(item_a)+ '-' + str(item_b)]) == 0 and len(processed_df [ processed_df [ column_name  ] == str(item_b) + '-' + str(item_a)]) == 0:\n",
    "    \n",
    "\n",
    "\n",
    "data = \"C:\\Users\\isaac\\Downloads\\groceries - groceries.csv\"\n",
    "process_data(data)\n",
    "\n",
    "#After running process data function, weshould have unique item list and a processed df.\n",
    "#Now, for each possible combination of unique items, we will check each column\n",
    "\n",
    "for item_a, item_b in itertools.combinations(unique_items, 2):\n",
    "    for column_name in process_data.columns:\n",
    "        # Flag to track if (a, b) is found in all sources\n",
    "        all_not_found = True\n",
    "        if check(processed_df, column_name, item_a, item_b):\n",
    "            # Check if (a, b) exists in the current dataset\n",
    "\n",
    "            # If check returns True, continue checking other sources\n",
    "            continue\n",
    "        else:\n",
    "            # If check returns False, set flag to False and break\n",
    "            all_not_found = False\n",
    "            break\n",
    "\n",
    "    # If the pair (a, b) is not found in any dataset, print the message\n",
    "    if all_not_found:\n",
    "        print(f\"{item_a}, {item_b} not found in data\")\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
